preprocess:
  max_len: 1024
  min_freq: 5
  is_demo: 0

model:
  model_type: 'GRU'    # 'GRU' or 'LSTM'
  embed_size: 128
  hidden_num: 256
  layer_num: 3
  dropout: 0.5
  agg_function: 'max'    # 'mean' & 'max' & 'attention' or ''
  attention_size: 128
  load_checkpoint: ''
  load_wv_path: '../word2vec/skip_gram.wv'

train:
  cuda_visible_devices: '0'
  multi_gpu: 0
  batch_size: 128
  optimizer: 'Adam'   # Adam & SGD
  lr: 0.0003
  momentum: 0.0
  weight_decay: 0.0    # torch L2
  lr_scheduler: ''   # 'step' & 'metric' & ''
  lr_step_size: 10    # 1000 = 10 * 100
  lr_step_gamma: 0.8
  lr_patience: 5   # 500 = 5 * 100
  lr_factor: 0.3
  train_steps: 20000
  steps_per_check: 100
  steps_per_checkpoint: 2000
  checkpoint_dir: 'RNN/'

eval: 
  submit_file: 'submit.csv'