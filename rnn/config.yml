preprocess:
  max_len: 1024
  min_freq: 5
  vocab_path: '../data/rnn.vocab'
  is_demo: 0

model:
  model_name: 'rnn'
  model_type: 'GRU'    # 'GRU' or 'LSTM'
  embed_size: 128
  hidden_num: 256
  layer_num: 3
  dropout: 0.5
  agg_function: 'Max'    # 'Mean' or 'Max' or 'Attention' or 'GRU' or 'Concat'
  attention_size: 128
  load_checkpoint_path: ''
  load_wv_path: '../word2vec/skip_gram.wv'

train:
  multi_gpu: 0
  batch_size: 128
  optimizer: 'Adam'   # Adam & SGD
  lr: 0.0003
  momentum: 0.0
  weight_decay: 0.0    # torch L2
  lr_scheduler: ''   # 'step' & 'metric' & ''
  lr_step_size: 2000
  lr_step_gamma: 0.8
  train_steps: 20000
  steps_per_check: 100
  steps_per_checkpoint: 5000
  checkpoint_path: 'RNN/'